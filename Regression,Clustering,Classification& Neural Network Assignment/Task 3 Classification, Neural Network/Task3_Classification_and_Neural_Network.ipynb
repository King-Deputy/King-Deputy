{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GtG7yZ92xQXm"
   },
   "source": [
    "# Task 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dYryzosJxVbB"
   },
   "source": [
    "## Classification and Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rV1dqLi2xbo9"
   },
   "source": [
    "### Importing Libraries and Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Necessary libraries are imported for data analysis and machine learning, NBA rookie data is loaded from as CSV file, and first few rows of the dataset after removing any missing values are shown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aCwmmn65xTNh",
    "outputId": "a6628916-0836-4da6-8c88-ac30291769bb"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "# Loading the NBA rookie data from the CSV file\n",
    "data = pd.read_csv('C:/Users/Dell/Documents/GitHub/King-Deputy/Regression,Clustering,Classification& Neural Network Assignment/Task 3 Classification, Neural Network/nba_rookie_data.csv')\n",
    "data = data.dropna()\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SldiFN-1yQOm"
   },
   "source": [
    "### Data Exploration and Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### This tasks help in understanding the data, identifying missing values, checking data types, exploring summary statistics, and understanding the distribution of the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y6bd_cfkxxuT",
    "outputId": "311f0e2d-67bb-4174-95cc-4c3fd17d762d"
   },
   "outputs": [],
   "source": [
    "# Checking for missing values in the dataset\n",
    "missing_values = data.isnull().sum()\n",
    "print(\"Missing Values:\\n\", missing_values)\n",
    "\n",
    "# Checking the data types of each column\n",
    "data_types = data.dtypes\n",
    "print(\"Data Types:\\n\", data_types)\n",
    "\n",
    "# Checking summary statistics of the dataset\n",
    "summary_stats = data.describe()\n",
    "print(\"Summary Statistics:\\n\", summary_stats)\n",
    "\n",
    "# Checking the distribution of the target variable\n",
    "target_distribution = data['TARGET_5Yrs'].value_counts()\n",
    "print(\"Target Variable Distribution:\\n\", target_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "tVpzm4Ffy92s",
    "outputId": "4902bf79-22c7-4650-a88f-18c57e7e530c"
   },
   "outputs": [],
   "source": [
    "count_0 = data['TARGET_5Yrs'].value_counts()[0]\n",
    "count_1 = data['TARGET_5Yrs'].value_counts()[1]\n",
    "\n",
    "# Creating a bar chart for the target variable\n",
    "plt.bar(['0', '1'], [count_0, count_1])\n",
    "plt.xlabel('TARGET_5Yrs')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Target Variable Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hRS6cIfg0mhm"
   },
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7B-kHQFfzuvZ",
    "outputId": "22af7ddc-068e-4cd9-9640-28c04fa82a4f"
   },
   "outputs": [],
   "source": [
    "# Seperating the features (X) and the target variable (y)\n",
    "X = data.drop(columns=['TARGET_5Yrs', 'Name'])\n",
    "y = data['TARGET_5Yrs']\n",
    "\n",
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Shape of X_train:\", X_train.shape)\n",
    "print(\"Shape of X_test:\", X_test.shape)\n",
    "print(\"Shape of y_train:\", y_train.shape)\n",
    "print(\"Shape of y_test:\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XkfEE92R1i42"
   },
   "source": [
    "### Building and Evaluating Machine Learning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GjK8BXlt1wt8"
   },
   "source": [
    "#### Using Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qVPmyYC51Be6",
    "outputId": "01f13cd1-1672-428e-edb0-b7983e6cde5a"
   },
   "outputs": [],
   "source": [
    "# Using Logistic Regression\n",
    "logistic_model = LogisticRegression(random_state=42)\n",
    "\n",
    "# Fitting the model on the training data\n",
    "logistic_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_logistic = logistic_model.predict(X_test)\n",
    "\n",
    "# Evaluating the Logistic Regression model\n",
    "accuracy_logistic = accuracy_score(y_test, y_pred_logistic)\n",
    "confusion_matrix_logistic = confusion_matrix(y_test, y_pred_logistic)\n",
    "\n",
    "print(\"Logistic Regression Model:\")\n",
    "print(\"Accuracy:\", accuracy_logistic)\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix_logistic)\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_logistic))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The Odd ratio is computed to understand the impact of each feature on the odds of the target variable. Positive odds ratios indicate an increase in the odds of the target variable, while negative values suggest a decrease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ujv4GO1uXL89",
    "outputId": "1e3af067-9b5f-4278-82cf-6654c7510519"
   },
   "outputs": [],
   "source": [
    "# Getting odds ratios\n",
    "odds_ratios = np.exp(logistic_model.coef_)\n",
    "\n",
    "# Creating a DataFrame to display the odds ratios\n",
    "odds_ratios_df = pd.DataFrame(odds_ratios, columns=X_train.columns, index=['Odds Ratio'])\n",
    "print(odds_ratios_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "azCwYykI1-8k",
    "outputId": "594bbdf3-ff9a-4b45-ce54-902a9e54b326"
   },
   "outputs": [],
   "source": [
    "# Visualise the Confusion Matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(confusion_matrix_logistic, annot=True, fmt=\"d\", cmap=\"Blues\", linewidths=.5, square=True, cbar=False)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Logistic Regression Confusion Matrix\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ugJRtz545DYm"
   },
   "source": [
    "#### Using GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AXIo1xlp4idi",
    "outputId": "9060cd1b-7796-4e13-c0ae-66a0ac3f2506"
   },
   "outputs": [],
   "source": [
    "#Using GaussianNB\n",
    "nb_model = GaussianNB()\n",
    "\n",
    "# Fitting the model on the training data\n",
    "nb_model.fit(X_train, y_train)\n",
    "\n",
    "# Predicting using the Gaussian Naive Bayes model\n",
    "y_pred_nb = nb_model.predict(X_test)\n",
    "\n",
    "nb_accuracy = accuracy_score(y_test, y_pred_nb)\n",
    "nb_precision = precision_score(y_test, y_pred_nb)\n",
    "nb_recall = recall_score(y_test, y_pred_nb)\n",
    "\n",
    "print(\"Gaussian Naive Bayes Model Metrics:\")\n",
    "print(f\"Accuracy: {nb_accuracy:.2f}\")\n",
    "print(f\"Precision: {nb_precision:.2f}\")\n",
    "print(f\"Recall: {nb_recall:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**These metrics provide an assessment of the Gaussian Naive Bayes model's performance on the test set, indicating its ability to correctly classify instances of each class.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Summary of the class-conditional distribution for each class is provided, indicating the mean and standard deviation for each feature. It helps in understanding the distribution of feature values within each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "skPUcSc9X9Mi",
    "outputId": "a8068d60-8b04-4a01-8716-a55cf2df0a24"
   },
   "outputs": [],
   "source": [
    "# Displaying class-conditional distribution summary\n",
    "for class_label in np.unique(y_train):\n",
    "    class_indices = (y_train == class_label)\n",
    "    class_data = X_train.loc[class_indices]\n",
    "\n",
    "    # Using mean and std to get class-conditional distribution summary\n",
    "    class_mean = class_data.mean()\n",
    "    class_std = class_data.std()\n",
    "\n",
    "    print(f\"\\nClass {class_label} - Mean:\")\n",
    "    print(class_mean)\n",
    "\n",
    "    print(f\"\\nClass {class_label} - Standard Deviation:\")\n",
    "    print(class_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "cW_IbFI15tvK",
    "outputId": "11b85647-0a63-40a6-a872-ba0b3d4fe999"
   },
   "outputs": [],
   "source": [
    "# Generating the confusion matrix for GaussianNB\n",
    "cm_nb = confusion_matrix(y_test, y_pred_nb)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_nb, annot=True, fmt='d', cmap='Blues', xticklabels=['Predicted 0', 'Predicted 1'], yticklabels=['Actual 0', 'Actual 1'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix - Gaussian Naive Bayes')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_ANRNouG62zf"
   },
   "source": [
    "#### Using Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qjDjF6uA6w3p"
   },
   "outputs": [],
   "source": [
    "# Standardize the feature data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The below code initializes, compiles, and trains a basic neural network (Sequential model) using Keras with TensorFlow backend. It then evaluates the model on the test set and prints accuracy, loss, and the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xHsRn_TC7bs7",
    "outputId": "db949df7-ad5e-419a-b5b5-d4ab553f9ad0"
   },
   "outputs": [],
   "source": [
    "# Initializing a Sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Adding input and hidden layers\n",
    "model.add(Dense(units=64, activation='relu', input_dim=X_train_scaled.shape[1]))\n",
    "model.add(Dense(units=32, activation='relu'))\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "# Compiling\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Fitting the model on the training data\n",
    "model.fit(X_train_scaled, y_train, epochs=10, batch_size=32, verbose=0)\n",
    "\n",
    "# Evaluating the model\n",
    "loss, accuracy = model.evaluate(X_test_scaled, y_test)\n",
    "\n",
    "print(\"Neural Network Model Metrics:\")\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Loss: {loss:.2f}\")\n",
    "\n",
    "y_pred_nn = model.predict(X_test_scaled)\n",
    "\n",
    "y_pred_nn_binary = (y_pred_nn > 0.5).astype(int)\n",
    "nn_cm = confusion_matrix(y_test, y_pred_nn_binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The gradients of the binary crossentropy loss with respect to the trainable variables in the neural network model is computed. The gradients are then printed for each variable. The GradientTape is used to record operations for automatic differentiation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FBDNGeS-aM6F",
    "outputId": "0c3b6c3d-59d2-45f8-a5df-210969212f33"
   },
   "outputs": [],
   "source": [
    "#Computing the gradients\n",
    "import tensorflow as tf\n",
    "\n",
    "# Convert y_test to a NumPy array and reshape it to have the same shape as predictions\n",
    "y_test_array = y_test.to_numpy().reshape(predictions.shape)\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    predictions = model(X_test_scaled, training=False)\n",
    "    loss = tf.keras.losses.binary_crossentropy(y_test_array, predictions)\n",
    "\n",
    "gradients = tape.gradient(loss, model.trainable_variables)\n",
    "\n",
    "# Printing the gradients\n",
    "print(\"\\nGradients with respect to the predictors:\")\n",
    "for variable, gradient in zip(model.trainable_variables, gradients):\n",
    "    print(f\"{variable.name}: {gradient.numpy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "FMiKK7Ni_qIl",
    "outputId": "8795514a-ae84-4c0b-c71a-941f6158ff87"
   },
   "outputs": [],
   "source": [
    "# Creating a heatmap to visualize the confusion matrix for Neural Network\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(nn_cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Predicted 0', 'Predicted 1'], yticklabels=['Actual 0', 'Actual 1'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix - Neural Network')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vnajNxVf9cA_"
   },
   "source": [
    "### Comparing the models and Visualizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "aq-awIYB76bK",
    "outputId": "4c78abc2-f438-400c-e31e-db2f5ce5be1a"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculating ROC curve and AUC for Logistic Regression\n",
    "fpr_logistic, tpr_logistic, _ = roc_curve(y_test, y_pred_logistic)\n",
    "roc_auc_logistic = roc_auc_score(y_test, y_pred_logistic)\n",
    "\n",
    "# Calculating ROC curve and AUC for Gaussian Naive Bayes\n",
    "fpr_nb, tpr_nb, _ = roc_curve(y_test, y_pred_nb)\n",
    "roc_auc_nb = roc_auc_score(y_test, y_pred_nb)\n",
    "\n",
    "# Calculating ROC curve and AUC for Neural Network\n",
    "fpr_nn, tpr_nn, _ = roc_curve(y_test, y_pred_nn)\n",
    "roc_auc_nn = roc_auc_score(y_test, y_pred_nn)\n",
    "\n",
    "# Plotting ROC curves\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr_logistic, tpr_logistic, label='Logistic Regression (AUC = %0.2f)' % roc_auc_logistic)\n",
    "plt.plot(fpr_nb, tpr_nb, label='Gaussian Naive Bayes (AUC = %0.2f)' % roc_auc_nb)\n",
    "plt.plot(fpr_nn, tpr_nn, label='Neural Network (AUC = %0.2f)' % roc_auc_nn)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC)')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C9B2KB-2AgNk"
   },
   "source": [
    "### Improving the Models by using Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "66j1Nm3vAl_X"
   },
   "source": [
    "#### Hyperparameter Tuning for Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 859
    },
    "id": "LezBafIq-EtL",
    "outputId": "0634d5ec-4166-442a-bb20-5bbb166e9ada"
   },
   "outputs": [],
   "source": [
    "# Defining the hyperparameter grid for Logistic Regression for model improvement\n",
    "param_grid_lr = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100],  # Regularization parameter\n",
    "    'max_iter': [100, 200, 300, 400]  # Maximum number of iterations\n",
    "}\n",
    "\n",
    "# Creating a Logistic Regression model\n",
    "lr_model = LogisticRegression()\n",
    "\n",
    "# Creating a GridSearchCV object for Logistic Regression\n",
    "lr_grid = GridSearchCV(lr_model, param_grid_lr, cv=5, scoring='accuracy')\n",
    "\n",
    "# Fitting the GridSearchCV object to ythe data\n",
    "lr_grid.fit(X_train, y_train)\n",
    "\n",
    "# Getting the best parameters and the best estimator\n",
    "best_params_lr = lr_grid.best_params_\n",
    "best_lr_model = lr_grid.best_estimator_\n",
    "\n",
    "y_pred_Tuned_logistic = best_lr_model.predict(X_test)\n",
    "\n",
    "# Evaluating the tuned Logistic Regression model\n",
    "accuracy_logistic_tuned = accuracy_score(y_test, y_pred_Tuned_logistic)\n",
    "confusion_matrix_logistic_tuned = confusion_matrix(y_test, y_pred_Tuned_logistic)\n",
    "\n",
    "print(\"Tuned Logistic Regression Model:\")\n",
    "print(\"Accuracy:\", accuracy_logistic_tuned)\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix_logistic_tuned)\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_Tuned_logistic))\n",
    "\n",
    "# Visualising the Confusion Matrix for the tuned Logistic model\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(confusion_matrix_logistic_tuned, annot=True, fmt=\"d\", cmap=\"Blues\", linewidths=.5, square=True, cbar=False)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Tuned Logistic Regression Confusion Matrix\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s42ZNXIcb5m_",
    "outputId": "e51fbe39-6023-4828-c270-00cb2bf74c56"
   },
   "outputs": [],
   "source": [
    "# Getting odds ratios for the Tuned Logistic Regression\n",
    "odds_ratios_Tunedlr = np.exp(best_lr_model.coef_)\n",
    "\n",
    "# Creating a DataFrame to display the odds ratios\n",
    "odds_ratios_Tunedlr_df = pd.DataFrame(odds_ratios_Tunedlr, columns=X_train.columns, index=['Odds Ratio'])\n",
    "print(odds_ratios_Tunedlr_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YhXdwWEoC7x8"
   },
   "source": [
    "#### Hyperparameter Tuning for Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "if7spTaGC-yh",
    "outputId": "9e4b2343-3ddf-4696-cead-0981aa4b81bb"
   },
   "outputs": [],
   "source": [
    "# Defining the hyperparameter grid for Neural Network\n",
    "param_grid_nn = {\n",
    "    'hidden_layer_sizes': [(50,), (100,), (50, 50), (100, 100)],\n",
    "    'alpha': [0.0001, 0.001, 0.01, 0.1],  # L2 regularization term\n",
    "    'max_iter': [100, 200, 300, 400]  # Maximum number of iterations\n",
    "}\n",
    "# Creating a Neural Network model\n",
    "nn_model = MLPClassifier()\n",
    "\n",
    "# Creating a GridSearchCV object for Neural Network\n",
    "nn_grid = GridSearchCV(nn_model, param_grid_nn, cv=5, scoring='accuracy')\n",
    "\n",
    "# Fitting the GridSearchCV object to the data\n",
    "nn_grid.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Getting the best parameters and the best estimator\n",
    "best_params_nn = nn_grid.best_params_\n",
    "best_nn_model = nn_grid.best_estimator_\n",
    "\n",
    "y_pred_Tuned_nn = best_nn_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluating the tuned neural network model\n",
    "accuracy = accuracy_score(y_test, y_pred_Tuned_nn)\n",
    "y_pred_nn_binary_Tuned = (y_pred_Tuned_nn > 0.5).astype(int)\n",
    "nn_cm_tuned = confusion_matrix(y_test, y_pred_nn_binary_Tuned)\n",
    "\n",
    "# Creating a heatmap to visualize the confusion matrix for the Tuned Neural Network\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(nn_cm_tuned, annot=True, fmt='d', cmap='Blues', xticklabels=['Predicted 0', 'Predicted 1'], yticklabels=['Actual 0', 'Actual 1'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix - Tuned Neural Network')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HY07jPDBIZVx"
   },
   "source": [
    "### Comparing the Tuned Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "1pMNIsGzIY7X",
    "outputId": "74f0aae5-27f2-4763-d336-4d639f90d221"
   },
   "outputs": [],
   "source": [
    "# Calculating ROC curve and AUC for Tuned Logistic Regression\n",
    "fpr_logistic_tuned, tpr_logistic_tuned, _ = roc_curve(y_test, y_pred_Tuned_logistic)\n",
    "roc_auc_logistic_tuned = roc_auc_score(y_test, y_pred_Tuned_logistic)\n",
    "\n",
    "# Calculating ROC curve and AUC for Gaussian Naive Bayes ( No Change)\n",
    "fpr_nb, tpr_nb, _ = roc_curve(y_test, y_pred_nb)\n",
    "roc_auc_nb = roc_auc_score(y_test, y_pred_nb)\n",
    "\n",
    "# Calculating ROC curve and AUC for Neural Network\n",
    "fpr_nn_tuned, tpr_nn_tuned, _ = roc_curve(y_test, y_pred_Tuned_nn)\n",
    "roc_auc_nn_tuned = roc_auc_score(y_test, y_pred_Tuned_nn)\n",
    "\n",
    "# Plotting ROC curves for the tuned model\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr_logistic_tuned, tpr_logistic_tuned, label='Tuned Logistic Regression (AUC = %0.2f)' % roc_auc_logistic_tuned)\n",
    "plt.plot(fpr_nb, tpr_nb, label='Gaussian Naive Bayes (AUC = %0.2f)' % roc_auc_nb)\n",
    "plt.plot(fpr_nn_tuned, tpr_nn_tuned, label='Tuned Neural Network (AUC = %0.2f)' % roc_auc_nn_tuned)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC)')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
